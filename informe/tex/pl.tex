\section{Programación Lineal}

En esta sección se planteará un modelo de Programación Lineal para la resolución de este problema. 
Primero se presentará la idea original, basada en una función no lineal con variables binarias, 
y luego se describirá un modelo lineal que aproxima la solución óptima.

Lo que se buscará al resolverlo con programación lineal en este informe es que, al recibir una secuencia
de $n$ maestros y un número $k$, se devuelva la menor diferencia posible entre el grupo de mayor suma y el
de menor suma, además de los grupos asignados.

La idea central consiste en introducir una variable binaria $y_{ij}$ que indique si el maestro $j$ pertenece al grupo $i$:

\[
y_{ij} =
\begin{cases}
1 & \text{si el maestro $j$ pertenece al grupo $i$},\\
0 & \text{en otro caso}.
\end{cases}
\]

Con esta definición, la función original a minimizar es:

\[
\min \sum_{i=1}^{k} \left( \sum_{j=1}^{n} x_j y_{ij} \right)^2.
\]

Dado que esta expresión no es lineal, se optará por formular un modelo lineal que proporcione una aproximación razonable.

\subsection{Variables}

\begin{itemize}
    \item $y_{ij} \in \{0,1\}$: indica si el maestro $j$ pertenece al grupo $i$.
    \item $s_i \in \mathbb{R}$: suma total de fuerzas asignadas al grupo $i$.
    \item $Z_{\max}, Z_{\min} \in \mathbb{R}$: valor máximo y mínimo, respectivamente, entre todas las sumas $s_i$.
\end{itemize}

\subsection{Restricciones}

Las restricciones del modelo aseguran la correcta asignación de maestros a grupos y la relación entre $s_i$, $Z_{\max}$ y $Z_{\min}$.

\begin{itemize}
    \item \textbf{Asignación de maestros:}  
    Lo principal será limitar a cuántos grupos $i$ puede pertenecer cada maestro $j$. En este caso se busca que cada maestro
    esté asignado a un solo grupo, por lo tanto, tendremos una restricción tal que:

    \[
    \sum_{i=1}^{k} y_{ij} = 1 \quad \forall j.
    \]

    Esto garantiza que ningún maestro quede sin asignar ni aparezca en más de un grupo.

    \item \textbf{Definición de las sumas $\mathbf{s_i}$:}  
    Para cada grupo $i$, la suma de fuerzas es igual a la suma de los valores $x_j$ de los maestros asignados a él:

    \[
    s_i = \sum_{j=1}^{n} x_j y_{ij} \quad \forall i.
    \]

    Se sumarán todas las fuerzas de cada maestro $j$ solo si pertenece al grupo $i$ ($y_{ij} = 1$).

    \item \textbf{Relación con $\mathbf{Z_{\max} \text{ y } Z_{\min}}$:} 
    Para que $Z_{\max}$ y $Z_{\min}$ representen efectivamente el mayor y el menor valor entre los $s_i$, se imponen:

    \[
    s_i \le Z_{\max} \quad \forall i,
    \]

    \[
    s_i \ge Z_{\min} \quad \forall i.
    \]
\end{itemize}

Se tendría un total de $n+3k$ inecuaciones.



\subsection{Función Objetivo}

La aproximación lineal consiste en minimizar la diferencia entre la suma más grande y la suma más pequeña:

\[
\min \left( Z_{\max} - Z_{\min} \right).
\]

Este criterio es razonable porque minimizar la diferencia entre los grupos tiende a equilibrar sus sumas, 
lo cual aproxima el objetivo original basado en la minimización de los cuadrados.


\subsection{Implementación en Python con PuLP}

\lstinputlisting[language=Python]{../prog_lineal.py}




\subsection{Mediciones}

Se tomaron mediciones de tiempo usando datos aleatorios para Backtracking y Programación Lineal. Se realizaron diversas repeticiones para obtener un mejor ajuste.
A continuación se muestra una comparación gráfica de los tiempos de ambos algoritmos:

\subsubsection*{Tiempos de Ejecución}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{img/comparacion_tiempos_pl_vs_bt.png}
\end{figure}

Se puede observar que dado un determinado momento, el tiempo de ejecucion del algoritmo por Programacion Lineal cae abruptamente con respecto al de Backtracking.
Esto probablemente se deba a los algoritmos que utiliza el solver implementado en la libreria de PuLP, Simplex y Branch and Bounds. El metodo Simplex es extremadamente rapido para obtener cotas globales y al combinarlo con Branch and Bounds se acaban podando enormes porciones del espacio de busqueda.
Backtracking en cambio no obtiene cotas globales, solo detecta conflictos locales, lo que explicaria por que en ciertos casos se nota un menor tiempo de ejecucion para Programacion Lineal a partir de cierto punto.


\subsubsection*{Ratio de la Aproximación}

Se analizará de qué manera varía la optimalidad de los resultados de este modelo. Para ello, se tomaron mediciones con conjuntos de datos aleatorios. Para simplificar el tiempo de procesamiento, se generaron datos con $n \leq 16$ y $k = 5$.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{img/ratio_pl_bt_1.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{img/ratio_pl_bt_2.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{img/ratio_pl_bt_3.png}
\end{figure}

El peor ratio obtenido fue de 1.001, que para tratarse del peor caso constituye una muy buena aproximación, especialmente si se considera que, en general, la media del ratio es significativamente más baja.

También es importante notar que, luego de $n=10$, la media del algoritmo por
Programación Lineal vuelve a acercarse al óptimo. Es esperable que, para ciertos valores de $k$ y $n$, el $ratio$ aumente.

